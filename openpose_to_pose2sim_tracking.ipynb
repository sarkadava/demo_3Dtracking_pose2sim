{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D motion tracking using multiple cameras with OpenPose and Pose2Sim\n",
    "\n",
    "<br>\n",
    "<div align=\"center\">Šárka Kadavá (kadava@leibniz-zas.de), Wim Pouw (wim.pouw@donders.ru.nl)</div>\n",
    "\n",
    "<img src=\"Images/envision_banner.png\" alt=\"isolated\" width=\"300\"/>\n",
    "\n",
    "# Info documents\n",
    "\n",
    "This python coding module shows how to perform 3D motion tracking on videos made with multiple cameras. First, we get estimation of 2D coordinates using OpenPose. Afterwards, we calibrate the cameras using checker board and we triangulate to get estimation of the coordinates in 3D space.\n",
    "\n",
    "location Repository: https://github.com/sarkadava/demo_3Dtracking_pose2sim/tree/main\n",
    "\n",
    "location Jupyter notebook: https://github.com/sarkadava/demo_3Dtracking_pose2sim/blob/main/openpose_to_pose2sim_tracking.ipynb\n",
    "\n",
    "If you wish to record a setup with multiple cameras, you can check module: https://envisionbox.org/embedded_multiple_webcam_record.html\n",
    "\n",
    "\n",
    "# Background\n",
    "\n",
    "The code below first estimates the 2D coordinates of each video. \n",
    "Then it uses a video with checkerboard calibration from each of the camera and finds the angles between the cameras. \n",
    "Then we run Pose2Sim to triangulate the three videos to get coordinates in 3D space.\n",
    "\n",
    "Note that we largely use material provided by OpenPose and Pose2sim creators.\n",
    "\n",
    "citation for OpenPose: \n",
    "\n",
    "Cao, Z., Simon, T., Wei, S. E., & Sheikh, Y. (2017). Realtime multi-person 2d pose estimation using part affinity fields. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 7291-7299).\n",
    "\n",
    "citation for Pose2Sim: \n",
    "\n",
    "Pagnon, D., Domalain, M., & Reveret, L. (2022). Pose2Sim: An open-source Python package for multiview markerless kinematics. Journal of Open Source Software, 7(77), 4362.\n",
    "\n",
    "Pagnon, D., Domalain, M., & Reveret, L. (2022). Pose2Sim: an end-to-end workflow for 3D markerless sports kinematics—part 2: accuracy. Sensors, 22(7), 2712.\n",
    "\n",
    "Pagnon, D., Domalain, M., & Reveret, L. (2021). Pose2Sim: an end-to-end workflow for 3D markerless sports kinematics—part 1: robustness. Sensors, 21(19), 6530.\n",
    "\n",
    "\n",
    "# Was this helpful?\n",
    "\n",
    "citation for this module: Kadavá, S., Pouw, W. (2024). 3D motion tracking using multiple cameras with OpenPose and Pose2Sim [the day you viewed the site]. Retrieved from: xxx\n",
    "\n",
    "\n",
    "# Requirements\n",
    "\n",
    "Make sure you install the requirements.txt for running this module (pip install -r requirements.txt)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the environment\n",
    "\n",
    "First, we prepare all the folders we will need\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:\\\\EnvisionBox_tracking\\\\demo_3Dtracking_pose2sim/videodata\\\\trial_0']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import glob\n",
    "\n",
    "# this is the current working directorz\n",
    "curfolder = os.path.abspath('./')\n",
    "\n",
    "\n",
    "# this is the folder where openpose lives\n",
    "openposefol = curfolder+'/openpose/'\n",
    "openpose_demo_loc = curfolder+'/openpose/bin/OpenPoseDemo.exe'\n",
    "# this is the model we are going to emploz\n",
    "model_to_employ = 'BODY_135'\n",
    "\n",
    "\n",
    "# in this folder, we have our folders with videos\n",
    "folderstotrack = glob.glob(curfolder+'/videodata/*')\n",
    "\n",
    "print(folderstotrack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\EnvisionBox_tracking\\demo_3Dtracking_pose2sim/videodata\\trial_0\n",
      "['D:\\\\EnvisionBox_tracking\\\\demo_3Dtracking_pose2sim/videodata\\\\trial_0/raw-2d\\\\0_1_trial_1_raw_cam1.avi', 'D:\\\\EnvisionBox_tracking\\\\demo_3Dtracking_pose2sim/videodata\\\\trial_0/raw-2d\\\\0_1_trial_1_raw_cam2.avi', 'D:\\\\EnvisionBox_tracking\\\\demo_3Dtracking_pose2sim/videodata\\\\trial_0/raw-2d\\\\0_1_trial_1_raw_cam3.avi']\n",
      "were going to send this to command prompt:   D:\\EnvisionBox_tracking\\demo_3Dtracking_pose2sim/openpose/bin/OpenPoseDemo.exe --model_pose BODY_135 --video D:\\EnvisionBox_tracking\\demo_3Dtracking_pose2sim/videodata\\trial_0/raw-2d\\0_1_trial_1_raw_cam1.avi --write_json D:\\EnvisionBox_tracking\\demo_3Dtracking_pose2sim/videodata\\trial_0/pose-2d/pose_cam1_json/ --write_video D:\\EnvisionBox_tracking\\demo_3Dtracking_pose2sim/videodata\\trial_0/pose-2d-trackingvideos/video0.avi \n",
      "were going to send this to command prompt:   D:\\EnvisionBox_tracking\\demo_3Dtracking_pose2sim/openpose/bin/OpenPoseDemo.exe --model_pose BODY_135 --video D:\\EnvisionBox_tracking\\demo_3Dtracking_pose2sim/videodata\\trial_0/raw-2d\\0_1_trial_1_raw_cam2.avi --write_json D:\\EnvisionBox_tracking\\demo_3Dtracking_pose2sim/videodata\\trial_0/pose-2d/pose_cam2_json/ --write_video D:\\EnvisionBox_tracking\\demo_3Dtracking_pose2sim/videodata\\trial_0/pose-2d-trackingvideos/video1.avi \n",
      "were going to send this to command prompt:   D:\\EnvisionBox_tracking\\demo_3Dtracking_pose2sim/openpose/bin/OpenPoseDemo.exe --model_pose BODY_135 --video D:\\EnvisionBox_tracking\\demo_3Dtracking_pose2sim/videodata\\trial_0/raw-2d\\0_1_trial_1_raw_cam3.avi --write_json D:\\EnvisionBox_tracking\\demo_3Dtracking_pose2sim/videodata\\trial_0/pose-2d/pose_cam3_json/ --write_video D:\\EnvisionBox_tracking\\demo_3Dtracking_pose2sim/videodata\\trial_0/pose-2d-trackingvideos/video2.avi \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def runcommand(command):\n",
    "    # run the command using subprocess for OPENPOSE TRACKING\n",
    "    try:\n",
    "        subprocess.run(command, shell=True, check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Command execution failed with error code {e.returncode}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"The OpenPoseDemo.exe executable was not found.\")\n",
    "\n",
    "# loop over the videofolders and prepare the folder structure\n",
    "for i in folderstotrack:\n",
    "    print(i)\n",
    "    os.chdir(openposefol)\n",
    "    # identify all avi files in folder\n",
    "    direc = glob.glob(i + '/raw-2d/' +'*.avi')\n",
    "\n",
    "    # 3 cameras\n",
    "    video0 = direc[0]\n",
    "    video1 = direc[1]\n",
    "    video2 = direc[2]\n",
    "\n",
    "    videolist = [video0, video1, video2]\n",
    "    print(videolist)\n",
    "    # make a new directory if it doesn't exist\n",
    "    if not os.path.exists(i+'/pose-2d/'):\n",
    "        os.makedirs(i+'/pose-2d/')\n",
    "    if not os.path.exists(i+'/pose-2d/pose_cam1_json/'):\n",
    "        os.makedirs(i+'/pose-2d/pose_cam1_json/')\n",
    "    if not os.path.exists(i+'/pose-2d/pose_cam2_json/'):\n",
    "        os.makedirs(i+'/pose-2d/pose_cam2_json/')\n",
    "    if not os.path.exists(i+'pose-2d/pose_cam3_json/'):\n",
    "        os.makedirs(i+'/pose-2d/pose_cam3_json/')\n",
    "    # also make directory for openpose videos (pose-2d-trackingvideos)\n",
    "    # make a new directory if it doesn't exist\n",
    "    if not os.path.exists(i+'/pose-2d-trackingvideos/'):\n",
    "        os.makedirs(i+'/pose-2d-trackingvideos/')\n",
    "\n",
    "    # initialize the pose2 folder\n",
    "    outputfol1 = i+'/pose-2d/pose_cam1_json/'\n",
    "    outputfol2 = i+'/pose-2d/pose_cam2_json/'\n",
    "    outputfol3 = i+'/pose-2d/pose_cam3_json/'\n",
    "\n",
    "    outputfollist = [outputfol1, outputfol2, outputfol3]\n",
    "    \n",
    "    # loop over each video and perform motion tracking\n",
    "    for it, j in enumerate(outputfollist):\n",
    "        #first track with openpose vid1\n",
    "        openposelocation = ' ' + openpose_demo_loc + ' '\n",
    "        model = '--model_pose' + ' ' + model_to_employ + ' '\n",
    "        video = '--video ' + videolist[it] + ' '\n",
    "        todo = '--write_json '\n",
    "        outputfol = j + ' '\n",
    "        videoadd = '--write_video '\n",
    "        videopath = i+'/pose-2d-trackingvideos/' + 'video'+str(it)+'.avi' + ' '\n",
    "        command = r' '+openposelocation+model+video+todo+outputfol+videoadd+videopath\n",
    "        print('were going to send this to command prompt: ' + command)\n",
    "        runcommand(command)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are left with 2D coordinates for each of the videos.\n",
    "\n",
    "## 3D estimation\n",
    "\n",
    "We will now calibrate the cameras to get their relative position towards each other, and triangulate the videos to estimate 3D coordinate from 2D coordinates.\n",
    "\n",
    "Again, we first load all the packages and set necessary folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.3\n",
      "4.6.0\n",
      "1.21.0\n"
     ]
    }
   ],
   "source": [
    "from Pose2Sim import Pose2Sim\n",
    "import os\n",
    "import subprocess\n",
    "import glob\n",
    "import pandas as pd\n",
    "from trc import TRCData\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the folder structure\n",
    "pose2simprjfolder = curfolder+'/Pose2Sim/Empty_project_ENVISION_settings'\n",
    "# here are stored videos\n",
    "inputfolders = curfolder+'/videodata/'\n",
    "folderstotrack = glob.glob(curfolder+'/videodata/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration and triangulation\n",
    "\n",
    "Now we will calibrate using the 3 videos with checkerboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial_0\n",
      "source = D:\\EnvisionBox_tracking\\demo_3Dtracking_pose2sim/Pose2Sim/Empty_project_ENVISION_settings/User/ to destination: D:\\EnvisionBox_tracking\\demo_3Dtracking_pose2sim/videodata\\trial_0/\n",
      "calibration started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Tracking of the person of interest for trial_0, for all frames.\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "Project directory: D:\\EnvisionBox_tracking\\demo_3Dtracking_pose2sim\\videodata\\trial_0\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 299/299 [00:01<00:00, 273.98it/s]\n",
      "\n",
      "--> Mean reprojection error for Neck point on all frames is 6.7 px, which roughly corresponds to 32.9 mm. \n",
      "--> In average, 1.0 cameras had to be excluded to reach the demanded 20 px error threshold.\n",
      "\n",
      "Tracked json files are stored in D:\\EnvisionBox_tracking\\demo_3Dtracking_pose2sim\\videodata\\trial_0\\pose-2d-tracked.\n",
      "Tracking took 1.13 s.\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Triangulation of 2D points for trial_0, for all frames.\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "Project directory: D:\\EnvisionBox_tracking\\demo_3Dtracking_pose2sim\\videodata\\trial_0\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 299/299 [00:01<00:00, 162.08it/s]\n",
      "D:\\EnvisionBox_tracking\\demo_3Dtracking_pose2sim\\Pose2Sim\\triangulate_3d.py:173: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  Q.to_csv(trc_o, sep='\\t', index=True, header=None, line_terminator='\\n')\n",
      "\n",
      "Mean reprojection error for RHip is 5.1 px (~ 0.025 m), reached with 1.0 excluded cameras. \n",
      "No frames were interpolated because 'interpolation_kind' was set to none. \n",
      "Mean reprojection error for RKnee is 5.0 px (~ 0.025 m), reached with 1.0 excluded cameras. \n",
      "No frames were interpolated because 'interpolation_kind' was set to none. \n",
      "Mean reprojection error for RAnkle is 3.8 px (~ 0.019 m), reached with 1.0 excluded cameras. \n",
      "No frames were interpolated because 'interpolation_kind' was set to none. \n",
      "Mean reprojection error for RBigToe is 2.4 px (~ 0.012 m), reached with 1.0 excluded cameras. \n",
      "No frames were interpolated because 'interpolation_kind' was set to none. \n",
      "Mean reprojection error for RSmallToe is 1.1 px (~ 0.005 m), reached with 1.0 excluded cameras. \n",
      "No frames were interpolated because 'interpolation_kind' was set to none. \n",
      "Mean reprojection error for RHeel is 4.9 px (~ 0.024 m), reached with 1.0 excluded cameras. \n",
      "No frames were interpolated because 'interpolation_kind' was set to none. \n",
      "Mean reprojection error for LHip is 9.3 px (~ 0.046 m), reached with 1.0 excluded cameras. \n",
      "No frames were interpolated because 'interpolation_kind' was set to none. \n",
      "Mean reprojection error for LKnee is 9.2 px (~ 0.045 m), reached with 1.0 excluded cameras. \n",
      "No frames were interpolated because 'interpolation_kind' was set to none. \n",
      "Mean reprojection error for LAnkle is 13.8 px (~ 0.068 m), reached with 1.0 excluded cameras. \n",
      "No frames were interpolated because 'interpolation_kind' was set to none. \n",
      "Mean reprojection error for LBigToe is 11.8 px (~ 0.058 m), reached with 1.0 excluded cameras. \n",
      "No frames were interpolated because 'interpolation_kind' was set to none. \n",
      "Mean reprojection error for LSmallToe is 12.9 px (~ 0.063 m), reached with 1.0 excluded cameras. \n",
      "No frames were interpolated because 'interpolation_kind' was set to none. \n",
      "Mean reprojection error for LHeel is 14.3 px (~ 0.07 m), reached with 1.0 excluded cameras. \n",
      "No frames were interpolated because 'interpolation_kind' was set to none. \n",
      "Mean reprojection error for Neck is 6.7 px (~ 0.033 m), reached with 1.0 excluded cameras. \n",
      "No frames were interpolated because 'interpolation_kind' was set to none. \n",
      "Mean reprojection error for Head is 9.9 px (~ 0.049 m), reached with 1.0 excluded cameras. \n",
      "No frames were interpolated because 'interpolation_kind' was set to none. \n",
      "Mean reprojection error for Nose is 8.1 px (~ 0.04 m), reached with 1.0 excluded cameras. \n",
      "No frames were interpolated because 'interpolation_kind' was set to none. \n",
      "Mean reprojection error for RShoulder is 5.8 px (~ 0.029 m), reached with 1.0 excluded cameras. \n",
      "No frames were interpolated because 'interpolation_kind' was set to none. \n",
      "Mean reprojection error for RElbow is 3.1 px (~ 0.015 m), reached with 1.0 excluded cameras. \n",
      "No frames were interpolated because 'interpolation_kind' was set to none. \n",
      "Mean reprojection error for RWrist is 4.7 px (~ 0.023 m), reached with 1.0 excluded cameras. \n",
      "No frames were interpolated because 'interpolation_kind' was set to none. \n",
      "Mean reprojection error for RThumb is 6.5 px (~ 0.032 m), reached with 1.01 excluded cameras. \n",
      "No frames were interpolated because 'interpolation_kind' was set to none. \n",
      "Mean reprojection error for RIndex is 6.4 px (~ 0.031 m), reached with 1.01 excluded cameras. \n",
      "No frames were interpolated because 'interpolation_kind' was set to none. \n",
      "Mean reprojection error for RPinky is 6.4 px (~ 0.031 m), reached with 1.0 excluded cameras. \n",
      "No frames were interpolated because 'interpolation_kind' was set to none. \n",
      "Mean reprojection error for LShoulder is 10.0 px (~ 0.049 m), reached with 1.0 excluded cameras. \n",
      "No frames were interpolated because 'interpolation_kind' was set to none. \n",
      "Mean reprojection error for LElbow is 12.0 px (~ 0.059 m), reached with 1.0 excluded cameras. \n",
      "No frames were interpolated because 'interpolation_kind' was set to none. \n",
      "Mean reprojection error for LWrist is 7.9 px (~ 0.039 m), reached with 1.0 excluded cameras. \n",
      "No frames were interpolated because 'interpolation_kind' was set to none. \n",
      "Mean reprojection error for LThumb is 6.5 px (~ 0.032 m), reached with 1.0 excluded cameras. \n",
      "No frames were interpolated because 'interpolation_kind' was set to none. \n",
      "Mean reprojection error for LIndex is 6.1 px (~ 0.03 m), reached with 1.0 excluded cameras. \n",
      "No frames were interpolated because 'interpolation_kind' was set to none. \n",
      "Mean reprojection error for LPinky is 6.1 px (~ 0.03 m), reached with 1.01 excluded cameras. \n",
      "No frames were interpolated because 'interpolation_kind' was set to none. \n",
      "\n",
      "--> Mean reprojection error for all points on all frames is 7.0 px, which roughly corresponds to 34.4 mm. \n",
      "Cameras were excluded if likelihood was below 0.1 and if the reprojection error was above 15 px.\n",
      "In average, 1.0 cameras had to be excluded to reach these thresholds.\n",
      "Camera cam1 was excluded 14% of the time, Camera cam2: 0%, and Camera cam3: 0%.\n",
      "\n",
      "3D coordinates are stored at D:\\EnvisionBox_tracking\\demo_3Dtracking_pose2sim\\videodata\\trial_0\\pose-3d\\trial_0_0-299.trc.\n",
      "Triangulation took 1.93 s.\n",
      "\n",
      "\n",
      "---------------------------------------------------------------------\n",
      "Filtering 3D coordinates for trial_0, for all frames.\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "Project directory: D:\\EnvisionBox_tracking\\demo_3Dtracking_pose2sim\\videodata\\trial_0\n",
      "D:\\EnvisionBox_tracking\\demo_3Dtracking_pose2sim\\Pose2Sim\\filter_3d.py:370: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  Q_filt.to_csv(trc_o, sep='\\t', index=False, header=None, line_terminator='\\n')\n",
      "--> Filter type: Gaussian. Standard deviation kernel: 2\n",
      "Filtered 3D coordinates are stored at D:\\EnvisionBox_tracking\\demo_3Dtracking_pose2sim\\videodata\\trial_0\\pose-3d\\trial_0_filt_0-299.trc.\n",
      "Exception in callback functools.partial(<function Kernel.enter_eventloop.<locals>.advance_eventloop at 0x00000287E6BCB5E0>)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in advance_eventloop\n",
      "    eventloop(self)\n",
      "  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\eventloops.py\", line 137, in loop_qt5\n",
      "    return loop_qt4(kernel)\n",
      "  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\eventloops.py\", line 119, in loop_qt4\n",
      "    _notify_stream_qt(kernel, kernel.shell_stream)\n",
      "  File \"C:\\Users\\u668173\\.conda\\envs\\multimodalmask\\lib\\site-packages\\ipykernel\\eventloops.py\", line 40, in _notify_stream_qt\n",
      "    notifier = QtCore.QSocketNotifier(fd, QtCore.QSocketNotifier.Read, kernel.app)\n",
      "AttributeError: type object 'QSocketNotifier' has no attribute 'Read'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# set framerate\n",
    "framerate = 60\n",
    "\n",
    "for i in folderstotrack:\n",
    "    os.chdir(i)\n",
    "    # get the sessionID\n",
    "    split = i.split(os.path.sep)\n",
    "    trialID = split[-1]\n",
    "    sessionID = trialID.split(\"_\")[-1]\n",
    "    \n",
    "    print(trialID)\n",
    "    # copy a folder in pose2simprjfolder and its contents to folders and add it to another folder using shutil\n",
    "    source1 = pose2simprjfolder+'/User/'\n",
    "    source2 = pose2simprjfolder+'/opensim/'\n",
    "    print('source = ' + source1 + ' to destination: ' + i+'/')\n",
    "    # copy the user and opensim folder, but only if they don't exist\n",
    "    if not os.path.exists(i+'/User/'):\n",
    "        shutil.copytree(source1, i+'/User/')\n",
    "    if not os.path.exists(i+'/opensim/'):\n",
    "        shutil.copytree(source2, i+'/opensim/')\n",
    "\n",
    "    print('calibration started')\n",
    "    # calibration videos are only in the first folders of a session, so trial_0\n",
    "    if '0' in trialID and not os.path.exists(i+'/calibration/Calib_checkerboard.toml'):\n",
    "    # loop through the calibration folders with a video\n",
    "    # then save every 10thm frame to an image in that folder \n",
    "        calib_folders = glob.glob(i+'/calibration/*')\n",
    "        print(calib_folders)\n",
    "        for c in calib_folders:\n",
    "            # split the path into its components\n",
    "            split = c.split(os.path.sep)\n",
    "            camIndex = split[-1]\n",
    "            input_video = c+'/'+sessionID+'_checker_'+camIndex+'.avi'\n",
    "            cap = cv2.VideoCapture(input_video)\n",
    "\n",
    "            # check if the video file was opened successfully\n",
    "            if not cap.isOpened():\n",
    "                print(\"Error: Couldn't open the video file.\")\n",
    "                exit()\n",
    "            output_dir = c+'/'\n",
    "\n",
    "            # frame counter\n",
    "            frame_count = 0\n",
    "\n",
    "            while True:\n",
    "                # read the next frame\n",
    "                ret, frame = cap.read()\n",
    "\n",
    "                if not ret:\n",
    "                    break  # break the loop if we reach the end of the video\n",
    "                \n",
    "                frame_count += 1\n",
    "\n",
    "                # save every 10th frame\n",
    "                if frame_count % 10 == 0:\n",
    "                    frame_filename = f\"{output_dir}frame_{frame_count}.png\"\n",
    "                    cv2.imwrite(frame_filename, frame)\n",
    "                    print(f\"Saved frame {frame_count}\")\n",
    "\n",
    "            # release the video capture object and close the video file\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "    \n",
    "    # calibrate only if it is the first folder of a session\n",
    "    if '0' in trialID: \n",
    "        # check if Calib_checkerboard.toml exists in the calibration folder\n",
    "        if not os.path.exists(i+'/calibration/Calib_checkerboard.toml'):\n",
    "            Pose2Sim.calibrateCams() # calibrate with checkerboard\n",
    "    \n",
    "    # else we copy the calibration files from the first folder\n",
    "    else:\n",
    "        # copy the calibration files from the first folder\n",
    "        source = inputfolders+'trial_0'+'/calibration/'\n",
    "        dest = i+'/calibration/'\n",
    "        print('source = ' + source + ' to destination: ' + dest)\n",
    "        # copy the calibration folder, but only with the .toml file\n",
    "        if not os.path.exists(i+'/calibration/'):\n",
    "            os.makedirs(i + '/calibration/')  # create the destination directory if it doesn't exist\n",
    "        # if there is no toml file, copy it\n",
    "        if not os.path.exists(i+'/calibration/Calib_checkerboard.toml'):\n",
    "            for toml_file in glob.glob(source + 'Calib_checkerboard.toml'):\n",
    "                shutil.copy(toml_file, dest)\n",
    "\n",
    "    Pose2Sim.track2D()  # you want to keep 90% percent of the cameras?\n",
    "    Pose2Sim.triangulate3D()\n",
    "    Pose2Sim.filter3D()\n",
    "\n",
    "    # check in the pose-3d folder\\\n",
    "    if not os.path.exists(i+'/pose-3d/'):\n",
    "        os.makedirs(i+'/pose-3d/')\n",
    "    posefolder = './pose-3d/'\n",
    "    # check any .trc files in the folder\n",
    "    trcfiles = glob.glob(posefolder + '*.trc')\n",
    "\n",
    "    # loop through files and convert to csv\n",
    "    for file in trcfiles:\n",
    "        # now convert trc data to csv\n",
    "        mocap_data = TRCData()\n",
    "        mocap_data.load(os.path.abspath(file))\n",
    "\n",
    "        num_frames = mocap_data['NumFrames']\n",
    "        markernames = mocap_data['Markers'] # the marker names are not\n",
    "\n",
    "        # convert movap_data to pandas dataframe\n",
    "        mocap_data_df = pd.DataFrame(mocap_data, columns=mocap_data['Markers'])\n",
    "\n",
    "        # each value within the dataframe consists a list of x,y,z coordinates, we want to seperate these out so that each marker and dimension has its own column\n",
    "        # first we create a list of column names\n",
    "        colnames = []\n",
    "        for marker in markernames:\n",
    "            colnames.append(marker + '_x')\n",
    "            colnames.append(marker + '_y')\n",
    "            colnames.append(marker + '_z')\n",
    "\n",
    "        # Create a new DataFrame to store separated values\n",
    "        new_df = pd.DataFrame()\n",
    "\n",
    "        # Iterate through each column in the original DataFrame\n",
    "        for column in mocap_data_df.columns:\n",
    "            # Extract the x, y, z values from each cell\n",
    "            xyz = mocap_data_df[column].tolist()\n",
    "            # Create a new DataFrame with the values in the cell separated into their own columns\n",
    "            xyz_df = pd.DataFrame(xyz, columns=[column + '_x', column + '_y', column + '_z'])\n",
    "            # Add the new columns to the new DataFrame\n",
    "            new_df = pd.concat([new_df, xyz_df], axis=1)\n",
    "\n",
    "        # add a new time column to the new dataframe assuming the framerate was 60fps\n",
    "        time = []\n",
    "        ts = 0\n",
    "        for i in range(0, int(num_frames)):\n",
    "            ts = ts + 1/framerate\n",
    "            time.append(ts)\n",
    "\n",
    "        # add the time column to the new dataframe\n",
    "        new_df['Time'] = time\n",
    "\n",
    "        #write pd dataframe to csv\n",
    "        new_df.to_csv(file+'.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can expect AttributeError when running this code in jupyter notebook. To our knowledge, it has nothing to do with the pose2sim workflow as such. If you run this script in terminal, this error is eliminated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "25a19fbe0a9132dfb9279d48d161753c6352f8f9478c2e74383d340069b907c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
